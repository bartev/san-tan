{"cells":[{"cell_type":"markdown","source":["d\n# XGBoost\n \nIf you are not using the DBR 7.x ML Runtime, you will need to install `ml.dmlc:xgboost4j-spark_2.12:1.0.0` from Maven, well as `xgboost` from PyPI.\n\n**NOTE:** There is currently only a distributed version of XGBoost for Scala, not Python. We will switch to Scala for that section."],"metadata":{}},{"cell_type":"markdown","source":["## Data Preparation\n\nLet's go ahead and index all of our categorical features, and set our label to be `log(price)`."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import log, col\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml import Pipeline\n\nfilePath = \"/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\"\nairbnbDF = spark.read.parquet(filePath)\n(trainDF, testDF) = airbnbDF.withColumn(\"label\", log(col(\"price\"))).randomSplit([.8, .2], seed=42)\n\ncategoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\nindexOutputCols = [x + \"Index\" for x in categoricalCols]\n\nstringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n\nnumericCols = [field for (field, dataType) in trainDF.dtypes if ((dataType == \"double\") & (field != \"price\") & (field != \"label\"))]\nassemblerInputs = indexOutputCols + numericCols\nvecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\npipeline = Pipeline(stages=[stringIndexer, vecAssembler])"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Scala\n\nDistributed XGBoost with Spark only has a Scala API, so we are going to create views of our DataFrames to use in Scala, as well as save our (untrained) pipeline to load in to Scala."],"metadata":{}},{"cell_type":"code","source":["trainDF.createOrReplaceTempView(\"trainDF\")\ntestDF.createOrReplaceTempView(\"testDF\")\n\nfileName = \"/tmp/xgboost_feature_pipeline\"\npipeline.write().overwrite().save(fileName)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## Load Data/Pipeline in Scala\n\nThis section is only available in Scala because there is no distributed Python API for XGBoost in Spark yet.\n\nLet's load in our data/pipeline that we defined in Python."],"metadata":{}},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.Pipeline\n\nval fileName = \"tmp/xgboost_feature_pipeline\"\nval pipeline = Pipeline.load(fileName)\n\nval trainDF = spark.table(\"trainDF\")\nval testDF = spark.table(\"testDF\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## XGBoost\n\nNow we are ready to train our XGBoost model!"],"metadata":{}},{"cell_type":"code","source":["%scala\n\nimport ml.dmlc.xgboost4j.scala.spark._\nimport org.apache.spark.sql.functions._\n\nval paramMap = List(\"num_round\" -> 100, \"eta\" -> 0.1, \"max_leaf_nodes\" -> 50, \"seed\" -> 42, \"missing\" -> 0).toMap\n\nval xgboostEstimator = new XGBoostRegressor(paramMap)\n\nval xgboostPipeline = new Pipeline().setStages(pipeline.getStages ++ Array(xgboostEstimator))\n\nval xgboostPipelineModel = xgboostPipeline.fit(trainDF)\nval xgboostLogPredictedDF = xgboostPipelineModel.transform(testDF)\n\nval expXgboostDF = xgboostLogPredictedDF.withColumn(\"prediction\", exp(col(\"prediction\")))\nexpXgboostDF.createOrReplaceTempView(\"expXgboostDF\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["## Evaluate\n\nNow we can evaluate how well our XGBoost model performed."],"metadata":{}},{"cell_type":"code","source":["expXgboostDF = spark.table(\"expXgboostDF\")\n\ndisplay(expXgboostDF.select(\"price\", \"prediction\"))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\nregressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n\nrmse = regressionEvaluator.evaluate(expXgboostDF)\nr2 = regressionEvaluator.setMetricName(\"r2\").evaluate(expXgboostDF)\nprint(f\"RMSE is {rmse}\")\nprint(f\"R2 is {r2}\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Export to Python\n\nWe can also export our XGBoost model to use in Python for fast inference on small datasets."],"metadata":{}},{"cell_type":"code","source":["%scala\n\nval nativeModelPath = \"xgboost_native_model\"\nval xgboostModel = xgboostPipelineModel.stages.last.asInstanceOf[XGBoostRegressionModel]\nxgboostModel.nativeBooster.saveModel(nativeModelPath)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Predictions in Python\n\nLet's pass in an example record to our Python XGBoost model and see how fast we can get predictions!!\n\nDon't forget to exponentiate!"],"metadata":{}},{"cell_type":"code","source":["%python\nimport numpy as np\nimport xgboost as xgb\nbst = xgb.Booster({'nthread': 4})\nbst.load_model(\"xgboost_native_model\")\n\n# Per https://stackoverflow.com/questions/55579610/xgboost-attributeerror-dataframe-object-has-no-attribute-feature-names, DMatrix did the trick\n\ndata = np.array([[0.0, 2.0, 0.0, 14.0, 1.0, 0.0, 0.0, 1.0, 37.72001, -122.39249, 2.0, 1.0, 1.0, 1.0, 2.0, 128.0, 97.0, 10.0, 10.0, 10.0, 10.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])\nlog_pred = bst.predict(xgb.DMatrix(data))\nprint(f\"The predicted price for this rental is ${np.exp(log_pred)[0]:.2f}\")\n"],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"11-2 XGBoost","notebookId":3114109954854665},"nbformat":4,"nbformat_minor":0}
