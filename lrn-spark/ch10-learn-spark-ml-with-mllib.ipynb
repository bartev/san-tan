{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `spark.ml`\n",
    "    * newer API based on DataFrames\n",
    "----    \n",
    "* `spark.mllib` (DON'T USE ME)\n",
    "    * original ML API based on RDD API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data used in this notebook is from SF housing data set from Inside Airbnb.\n",
    "\n",
    "`dev/github-bv/LearningSparkV2/databricks-datasets/learning-spark-v2/sf-airbnb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[*]')\n",
    "         .appName(\"spark-ml-ch-10b\")\n",
    "         .config('ui.showConsoleProgress', 'false')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_fname(fname):\n",
    "    import os.path as path\n",
    "    data_dir = '~/dev/github-bv/LearningSparkV2/databricks-datasets/learning-spark-v2/'\n",
    "    return path.expanduser(path.join(data_dir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline API provides a high-level API built on top of DataFrames to organize ML worlflow\n",
    "* composed of a series of `transformers` and `estimators`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transformer\n",
    "    * DF -> DF + 1 or more columns appended\n",
    "    * has `.transform()` method\n",
    "* Estimator\n",
    "    * DF -> Model (Transformer)\n",
    "    * learns ('fits') params\n",
    "    * has `.fit()` method\n",
    "* Pipeline\n",
    "    * organize a series of transformers and estimators into a single model\n",
    "    * Pipeline is an `estimator`\n",
    "    * `pipeline.fit()` returns a `PipelineModel`, which is a `transformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They've done some cleansing already. See Databricks communitiy edition notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = db_fname('sf-airbnb/sf-airbnb-clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnbDF = spark.read.parquet(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|neighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|      Western Addition|Entire home/apt|     1.0|      1.0|            180.0|170.0|\n",
      "|        Bernal Heights|Entire home/apt|     2.0|      1.0|            111.0|235.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|             17.0| 65.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|              8.0| 65.0|\n",
      "|      Western Addition|Entire home/apt|     2.0|      1.5|             27.0|785.0|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnbDF.select('neighbourhood_cleansed', 'room_type', 'bedrooms', 'bathrooms', 'number_of_reviews', 'price').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5758 rows in the training set, and 1388 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = airbnbDF.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Features with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression (like many other algorithms in Spark) requires that **all the input features are contained within a single vector in your DataFrame**. Thus, we need to transform our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `VectorAssembler` to combine all columns into a single vector. https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+\n",
      "|bedrooms|features|price|\n",
      "+--------+--------+-----+\n",
      "|     1.0|   [1.0]|200.0|\n",
      "|     1.0|   [1.0]|250.0|\n",
      "|     3.0|   [3.0]|250.0|\n",
      "|     1.0|   [1.0]| 45.0|\n",
      "|     1.0|   [1.0]|115.0|\n",
      "|     1.0|   [1.0]| 70.0|\n",
      "|     1.0|   [1.0]|105.0|\n",
      "|     1.0|   [1.0]| 86.0|\n",
      "|     1.0|   [1.0]|100.0|\n",
      "|     2.0|   [2.0]|220.0|\n",
      "+--------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols = ['bedrooms'], outputCol='features')\n",
    "vecTrainDF = vecAssembler.transform(trainDF)\n",
    "vecTrainDF.select('bedrooms','features', 'price').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecAssembler.getInputCols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'features'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecAssembler.getOutputCol()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Estimators to Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='price')\n",
    "lrModel = lr.fit(vecTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.regression.LinearRegressionModel"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lrModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.regression.LinearRegression"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lr.fit()` returns a `LinearRegressionModel` (lrModel), which is a `transformer`. In other words, the **output** of an estimatorâ€™s `fit()` method is a `transformer`. Once the estimator has learned the parameters, the transformer can apply these parameters to new data points to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula for the linear regression line is  price = 119.32 x bedrooms + 54.11\n"
     ]
    }
   ],
   "source": [
    "m = round(lrModel.coefficients[0], 2)\n",
    "b = round(lrModel.intercept,2)\n",
    "\n",
    "print(f\"\"\"The formula for the linear regression line is  price = {m} x bedrooms + {b}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([119.3164])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = lrModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LinearRegression_96b02464c14f', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LinearRegression_96b02464c14f', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='labelCol', doc='label column name'): 'price',\n",
       " Param(parent='LinearRegression_96b02464c14f', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError',\n",
       " Param(parent='LinearRegression_96b02464c14f', name='maxIter', doc='maximum number of iterations (>= 0)'): 100,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LinearRegression_96b02464c14f', name='regParam', doc='regularization parameter (>= 0)'): 0.0,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto',\n",
       " Param(parent='LinearRegression_96b02464c14f', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LinearRegression_96b02464c14f', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: \t2\n",
      "elasticNetParam: \t0.0\n",
      "epsilon: \t1.35\n",
      "featuresCol: \tfeatures\n",
      "fitIntercept: \tTrue\n",
      "labelCol: \tprice\n",
      "loss: \tsquaredError\n",
      "maxIter: \t100\n",
      "predictionCol: \tprediction\n",
      "regParam: \t0.0\n",
      "solver: \tauto\n",
      "standardization: \tTrue\n",
      "tol: \t1e-06\n"
     ]
    }
   ],
   "source": [
    "for m in mp:\n",
    "    print(f'{m.name}: \\t{mp[m]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipelineModel` is a `transformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it to our test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'host_total_listings_count',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'price',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na',\n",
       " 'features',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+------------------+\n",
      "|bedrooms|features|price|        prediction|\n",
      "+--------+--------+-----+------------------+\n",
      "|     1.0|   [1.0]|130.0|173.42588969100558|\n",
      "|     1.0|   [1.0]| 85.0|173.42588969100558|\n",
      "|     1.0|   [1.0]| 95.0|173.42588969100558|\n",
      "|     1.0|   [1.0]|128.0|173.42588969100558|\n",
      "|     1.0|   [1.0]|250.0|173.42588969100558|\n",
      "|     1.0|   [1.0]| 95.0|173.42588969100558|\n",
      "|     1.0|   [1.0]|105.0|173.42588969100558|\n",
      "|     0.0|   [0.0]|125.0| 54.10946937938496|\n",
      "|     3.0|   [3.0]|405.0|412.05873031424676|\n",
      "|     1.0|   [1.0]| 72.0|173.42588969100558|\n",
      "+--------+--------+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preDF.select('bedrooms', 'features', 'price', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical values into numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark uses a `SparseVector` when the majority of entries are 0, so OHE does not massively increase consumption of memory or compute resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple ways to one-hot encode data in Spark\n",
    "\n",
    "1. Use `StringIndexer` and `OneHotEncoder`\n",
    "\n",
    "  * apply `StringIndexer` estimator to convert categorical values into category indices (ordered by label frequencies)\n",
    "  * pass output to `OneHotEncoder` (`OneHotEncoderEstimator` for us, since we're using Spark 2.4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, OneHotEncoderEstimator\n",
    "\n",
    "# categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == 'string']\n",
    "# indexOutputCols = [x + 'Index' for x in categoricalCols]\n",
    "# oheOutputCols = [x + 'OHE' for x in categoricalCols]\n",
    "\n",
    "# stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "#                               outputCols=indexOutputCols,\n",
    "#                               handleInvalid='skip')\n",
    "# oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "#                            outputCols=oheOutputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fields = [field for (field, dataType) in trainDF.dtypes if dataType == 'string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'neighbourhood_cleansed',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'bed_type']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string_indexer(col_name):\n",
    "    \"\"\"valid values of handleInvalid\n",
    "    skip (filter rows)\n",
    "    error (throw an error)\n",
    "    keep (put in a special additional bucket)\n",
    "    \n",
    "    NOTE: spark 3.0 will accept multple columns as input/output\n",
    "    \"\"\"\n",
    "    encoded_col_name = f'{col_name}_Index'\n",
    "    string_indexer = StringIndexer(inputCol=col_name, \n",
    "                                   outputCol=encoded_col_name, \n",
    "                                   handleInvalid='keep')\n",
    "    return string_indexer\n",
    "\n",
    "def make_one_hot_encoder(col_names):\n",
    "    \"\"\"each `*_OHE` column will be a SparseVector after fitting and transformation\n",
    "    \n",
    "    Usage:\n",
    "    ohe_room_type = make_one_hot_encoder(['room_type'])\n",
    "    encoded_room_type = ohe_room_type.fit(transformed_room_type)\n",
    "\n",
    "    encoded_room_type.transform(transformed_room_type).show()\n",
    "    \n",
    "    +---------------+-----+---------------+-------------+\n",
    "    |      room_type|price|room_type_Index|room_type_OHE|\n",
    "    +---------------+-----+---------------+-------------+\n",
    "    |   Private room|200.0|            1.0|(3,[1],[1.0])|\n",
    "    |Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
    "    |Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
    "    \"\"\"\n",
    "    input_col_names = [f'{col_name}_Index' for col_name in col_names]\n",
    "    output_col_names = [f'{col_name}_OHE' for col_name in col_names]\n",
    "    estimator = OneHotEncoderEstimator(inputCols=input_col_names,\n",
    "                                  outputCols=output_col_names)\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages_cat_str_index = [make_string_indexer(c) for c in cat_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "oheEncoder = make_one_hot_encoder(cat_fields)\n",
    "oheOutputCols = oheEncoder.getOutputCols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='OneHotEncoderEstimator_cad88dda0193', name='handleInvalid', doc=\"How to handle invalid data during transform(). Options are 'keep' (invalid data presented as an extra categorical feature) or error (throw an error). Note that this Param is only used during transform; during fitting, invalid data will result in an error.\"): 'error',\n",
       " Param(parent='OneHotEncoderEstimator_cad88dda0193', name='dropLast', doc='whether to drop the last category'): True,\n",
       " Param(parent='OneHotEncoderEstimator_cad88dda0193', name='inputCols', doc='input column names.'): ['host_is_superhost_Index',\n",
       "  'cancellation_policy_Index',\n",
       "  'instant_bookable_Index',\n",
       "  'neighbourhood_cleansed_Index',\n",
       "  'property_type_Index',\n",
       "  'room_type_Index',\n",
       "  'bed_type_Index'],\n",
       " Param(parent='OneHotEncoderEstimator_cad88dda0193', name='outputCols', doc='output column names.'): ['host_is_superhost_OHE',\n",
       "  'cancellation_policy_OHE',\n",
       "  'instant_bookable_OHE',\n",
       "  'neighbourhood_cleansed_OHE',\n",
       "  'property_type_OHE',\n",
       "  'room_type_OHE',\n",
       "  'bed_type_OHE']}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheEncoder.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_total_listings_count',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericCols = [field for (field, dataType) in trainDF.dtypes if ((dataType == 'double') & (field != 'price'))]\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = oheOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost_OHE',\n",
       " 'cancellation_policy_OHE',\n",
       " 'instant_bookable_OHE',\n",
       " 'neighbourhood_cleansed_OHE',\n",
       " 'property_type_OHE',\n",
       " 'room_type_OHE',\n",
       " 'bed_type_OHE',\n",
       " 'host_total_listings_count',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### What does `StringIndexer` do?\n",
    "\n",
    "* `StringIndexer` creates an estimator that will convert a column of strings to a column of numbers ordered by frequency\n",
    "* to use it, `.fit()` your dataframe to get a `model` object out\n",
    "* then, `.transform()` new data to append the indexed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Make the indexer object (no fitting yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "se_1 = make_string_indexer('room_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `.fit()` the indexer object (returns a `model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|      room_type|price|\n",
      "+---------------+-----+\n",
      "|   Private room|200.0|\n",
      "|Entire home/apt|250.0|\n",
      "|Entire home/apt|250.0|\n",
      "|   Private room| 45.0|\n",
      "|   Private room|115.0|\n",
      "|   Private room| 70.0|\n",
      "|   Private room|105.0|\n",
      "|   Private room| 86.0|\n",
      "|Entire home/apt|100.0|\n",
      "|Entire home/apt|220.0|\n",
      "|Entire home/apt|110.0|\n",
      "|   Private room|130.0|\n",
      "|   Private room|100.0|\n",
      "|Entire home/apt|350.0|\n",
      "|   Private room|159.0|\n",
      "|Entire home/apt|200.0|\n",
      "|Entire home/apt|250.0|\n",
      "|Entire home/apt|299.0|\n",
      "|Entire home/apt|250.0|\n",
      "|   Private room| 95.0|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select('room_type', 'price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "se_1_model = se_1.fit(trainDF.select('room_type', 'price'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `.transform()` some data using the fitted indexer object (the `model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------------+\n",
      "|      room_type|price|room_type_Index|\n",
      "+---------------+-----+---------------+\n",
      "|   Private room|200.0|            1.0|\n",
      "|Entire home/apt|250.0|            0.0|\n",
      "|Entire home/apt|250.0|            0.0|\n",
      "|   Private room| 45.0|            1.0|\n",
      "|   Private room|115.0|            1.0|\n",
      "|   Private room| 70.0|            1.0|\n",
      "|   Private room|105.0|            1.0|\n",
      "|   Private room| 86.0|            1.0|\n",
      "|Entire home/apt|100.0|            0.0|\n",
      "|Entire home/apt|220.0|            0.0|\n",
      "|Entire home/apt|110.0|            0.0|\n",
      "|   Private room|130.0|            1.0|\n",
      "|   Private room|100.0|            1.0|\n",
      "|Entire home/apt|350.0|            0.0|\n",
      "|   Private room|159.0|            1.0|\n",
      "|Entire home/apt|200.0|            0.0|\n",
      "|Entire home/apt|250.0|            0.0|\n",
      "|Entire home/apt|299.0|            0.0|\n",
      "|Entire home/apt|250.0|            0.0|\n",
      "|   Private room| 95.0|            1.0|\n",
      "+---------------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_room_type = se_1_model.transform(trainDF.select('room_type', 'price'))\n",
    "transformed_room_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------------+-------------+\n",
      "|      room_type|price|room_type_Index|room_type_OHE|\n",
      "+---------------+-----+---------------+-------------+\n",
      "|   Private room|200.0|            1.0|(3,[1],[1.0])|\n",
      "|Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
      "|   Private room| 45.0|            1.0|(3,[1],[1.0])|\n",
      "|   Private room|115.0|            1.0|(3,[1],[1.0])|\n",
      "|   Private room| 70.0|            1.0|(3,[1],[1.0])|\n",
      "|   Private room|105.0|            1.0|(3,[1],[1.0])|\n",
      "|   Private room| 86.0|            1.0|(3,[1],[1.0])|\n",
      "|Entire home/apt|100.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|220.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|110.0|            0.0|(3,[0],[1.0])|\n",
      "|   Private room|130.0|            1.0|(3,[1],[1.0])|\n",
      "|   Private room|100.0|            1.0|(3,[1],[1.0])|\n",
      "|Entire home/apt|350.0|            0.0|(3,[0],[1.0])|\n",
      "|   Private room|159.0|            1.0|(3,[1],[1.0])|\n",
      "|Entire home/apt|200.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|299.0|            0.0|(3,[0],[1.0])|\n",
      "|Entire home/apt|250.0|            0.0|(3,[0],[1.0])|\n",
      "|   Private room| 95.0|            1.0|(3,[1],[1.0])|\n",
      "+---------------+-----+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ohe_room_type = make_one_hot_encoder(['room_type'])\n",
    "encoded_room_type = ohe_room_type.fit(transformed_room_type)\n",
    "\n",
    "encoded_room_type.transform(transformed_room_type).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      room_type|\n",
      "+---------------+\n",
      "|    Shared room|\n",
      "|Entire home/apt|\n",
      "|   Private room|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_room_type.('room_type').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RFormula`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "rFormula = RFormula(formula='price ~.',\n",
    "                    featuresCol='features',\n",
    "                    labelCol='price',\n",
    "                    handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_transformer = rFormula.fit(trainDF.select('room_type', 'price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+-------------+\n",
      "|      room_type|price|     features|\n",
      "+---------------+-----+-------------+\n",
      "|   Private room|200.0|[0.0,1.0,0.0]|\n",
      "|Entire home/apt|250.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|250.0|[1.0,0.0,0.0]|\n",
      "|   Private room| 45.0|[0.0,1.0,0.0]|\n",
      "|   Private room|115.0|[0.0,1.0,0.0]|\n",
      "|   Private room| 70.0|[0.0,1.0,0.0]|\n",
      "|   Private room|105.0|[0.0,1.0,0.0]|\n",
      "|   Private room| 86.0|[0.0,1.0,0.0]|\n",
      "|Entire home/apt|100.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|220.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|110.0|[1.0,0.0,0.0]|\n",
      "|   Private room|130.0|[0.0,1.0,0.0]|\n",
      "|   Private room|100.0|[0.0,1.0,0.0]|\n",
      "|Entire home/apt|350.0|[1.0,0.0,0.0]|\n",
      "|   Private room|159.0|[0.0,1.0,0.0]|\n",
      "|Entire home/apt|200.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|250.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|299.0|[1.0,0.0,0.0]|\n",
      "|Entire home/apt|250.0|[1.0,0.0,0.0]|\n",
      "|   Private room| 95.0|[0.0,1.0,0.0]|\n",
      "+---------------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_transformer.transform(trainDF.select('room_type', 'price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_transformer = rFormula.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|room_type      |price|features                                                                                                                                                                                                                                 |\n",
      "+---------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Private room   |200.0|(104,[0,4,8,43,46,47,49,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,37.7431,-122.44509,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                                      |\n",
      "|Entire home/apt|250.0|(104,[0,4,8,10,28,46,47,48,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.72979,-122.37094,1.0,1.0,2.0,1.0,1.0,1.0,1.0,180.0,1.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                            |\n",
      "|Entire home/apt|250.0|(104,[0,4,8,10,28,46,47,49,73,76,77,78,79,80,85,87,88,89,90,91,92,93,97,98,99,100,101,102,103],[1.0,1.0,1.0,1.0,1.0,37.73072,-122.38907,1.0,1.0,6.0,3.0,3.0,3.0,1.0,30.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|Private room   |45.0 |(104,[0,4,8,10,28,46,47,49,74,76,77,78,79,80,85,87,88,89,90,91,92,93,97,98,99,100,101,102,103],[1.0,1.0,1.0,1.0,1.0,37.7325,-122.39221,1.0,1.0,1.0,1.0,1.0,1.0,1.0,31.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|Private room   |115.0|(104,[0,4,8,10,28,46,47,49,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.7352,-122.38566,1.0,1.0,2.0,1.0,1.0,1.0,1.0,2.0,100.0,96.0,10.0,9.0,10.0,10.0,9.0,10.0])                                                |\n",
      "|Private room   |70.0 |(104,[0,4,8,10,28,46,47,49,74,76,77,78,79,80,85,87,88,89,90,91,92,93,97,98,99,100,101,102,103],[1.0,1.0,1.0,1.0,1.0,37.73555,-122.39779,1.0,1.0,1.0,1.0,1.0,1.0,1.0,30.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|Private room   |105.0|(104,[0,4,8,10,16,46,47,50,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.7326,-122.41423,1.0,1.0,2.0,1.5,1.0,1.0,1.0,2.0,36.0,96.0,10.0,10.0,10.0,10.0,10.0,10.0])                                               |\n",
      "|Private room   |86.0 |(104,[0,4,8,10,16,46,47,49,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.73615,-122.41245,1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,194.0,91.0,9.0,9.0,10.0,10.0,9.0,9.0])                                                 |\n",
      "|Entire home/apt|100.0|(104,[0,4,8,10,16,46,47,48,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.73765,-122.41247,1.0,1.0,4.0,1.0,1.0,2.0,1.0,2.0,4.0,95.0,10.0,10.0,10.0,9.0,9.0,10.0])                                                 |\n",
      "|Entire home/apt|220.0|(104,[0,4,8,10,16,46,47,49,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.73826,-122.41693,1.0,1.0,4.0,1.0,2.0,2.0,1.0,4.0,2.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                              |\n",
      "|Entire home/apt|110.0|(104,[0,4,8,10,16,46,47,51,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.73994,-122.41502,1.0,1.0,3.0,1.0,1.0,2.0,1.0,30.0,2.0,100.0,10.0,9.0,10.0,10.0,10.0,10.0])                                              |\n",
      "|Private room   |130.0|(104,[0,4,8,10,16,46,47,49,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.7418,-122.41674,1.0,1.0,3.0,1.0,1.0,1.0,1.0,2.0,5.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                               |\n",
      "|Private room   |100.0|(104,[0,4,8,10,16,46,47,51,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.7422,-122.42091,1.0,1.0,4.0,1.0,1.0,3.0,1.0,3.0,49.0,95.0,10.0,10.0,10.0,10.0,10.0,9.0])                                                |\n",
      "|Entire home/apt|350.0|(104,[0,4,8,10,16,46,47,48,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.74387,-122.42338,1.0,1.0,4.0,2.0,3.0,2.0,1.0,30.0,10.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0])                                             |\n",
      "|Private room   |159.0|(104,[0,4,8,10,16,46,47,49,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.74473,-122.41516,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                              |\n",
      "|Entire home/apt|200.0|(104,[0,4,8,10,16,46,47,49,73,76,77,78,79,82,85,87,88,89,90,91,92,93,97,98,99,100,101,102,103],[1.0,1.0,1.0,1.0,1.0,37.74494,-122.41034,1.0,1.0,4.0,2.0,2.0,2.0,1.0,30.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|Entire home/apt|250.0|(104,[0,4,8,10,16,46,47,48,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.74552,-122.41195,1.0,1.0,2.0,2.0,1.0,1.0,1.0,2.0,4.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                              |\n",
      "|Entire home/apt|299.0|(104,[0,4,8,10,16,46,47,51,73,76,77,78,79,80,85,87,88,89,90,91,92,93,97,98,99,100,101,102,103],[1.0,1.0,1.0,1.0,1.0,37.74605,-122.42209,1.0,1.0,4.0,1.0,2.0,3.0,1.0,2.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|Entire home/apt|250.0|(104,[0,4,8,10,16,46,47,49,73,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.74697,-122.41193,1.0,1.0,3.0,1.0,2.0,2.0,1.0,2.0,15.0,96.0,10.0,10.0,10.0,10.0,10.0,10.0])                                              |\n",
      "|Private room   |95.0 |(104,[0,4,8,10,15,46,47,50,74,76,77,78,79,80,85,86,87,88,89,90,91,92,93],[1.0,1.0,1.0,1.0,1.0,37.758,-122.42991,1.0,1.0,2.0,1.5,1.0,1.0,1.0,2.0,27.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                               |\n",
      "+---------------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_transformer.transform(trainDF).select('room_type', 'price', 'features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to one-hot encode categorical features for tree-based methods, and it will often make your tree-based models worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol='price', featuresCol='features')\n",
    "pipeline = Pipeline(stages= stages_cat_str_index + [oheEncoder, vecAssembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[host_is_superhost: string, cancellation_policy: string, instant_bookable: string, host_total_listings_count: double, neighbourhood_cleansed: string, latitude: double, longitude: double, property_type: string, room_type: string, accommodates: double, bathrooms: double, bedrooms: double, beds: double, bed_type: string, minimum_nights: double, number_of_reviews: double, review_scores_rating: double, review_scores_accuracy: double, review_scores_cleanliness: double, review_scores_checkin: double, review_scores_communication: double, review_scores_location: double, review_scores_value: double, price: double, bedrooms_na: double, bathrooms_na: double, beds_na: double, review_scores_rating_na: double, review_scores_accuracy_na: double, review_scores_cleanliness_na: double, review_scores_checkin_na: double, review_scores_communication_na: double, review_scores_location_na: double, review_scores_value_na: double, host_is_superhost_Index: double, cancellation_policy_Index: double, instant_bookable_Index: double, neighbourhood_cleansed_Index: double, property_type_Index: double, room_type_Index: double, bed_type_Index: double, property_type_OHE: vector, room_type_OHE: vector, instant_bookable_OHE: vector, bed_type_OHE: vector, cancellation_policy_OHE: vector, host_is_superhost_OHE: vector, neighbourhood_cleansed_OHE: vector, features: vector, prediction: double]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "predDF = pipelineModel.transform(testDF)\n",
    "\n",
    "predDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'host_total_listings_count',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'price',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na',\n",
       " 'host_is_superhost_Index',\n",
       " 'cancellation_policy_Index',\n",
       " 'instant_bookable_Index',\n",
       " 'neighbourhood_cleansed_Index',\n",
       " 'property_type_Index',\n",
       " 'room_type_Index',\n",
       " 'bed_type_Index',\n",
       " 'property_type_OHE',\n",
       " 'room_type_OHE',\n",
       " 'instant_bookable_OHE',\n",
       " 'bed_type_OHE',\n",
       " 'cancellation_policy_OHE',\n",
       " 'host_is_superhost_OHE',\n",
       " 'neighbourhood_cleansed_OHE',\n",
       " 'features',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+--------------------+\n",
      "|price|        prediction|            features|\n",
      "+-----+------------------+--------------------+\n",
      "|130.0|-50.08206919874374|(104,[0,4,8,27,45...|\n",
      "| 85.0| 69.30273500843668|(104,[0,4,8,27,46...|\n",
      "| 95.0|122.44764330428825|(104,[0,4,8,27,48...|\n",
      "|128.0|-73.85987476664286|(104,[0,4,8,15,45...|\n",
      "|250.0| 122.6754680966792|(104,[0,4,8,15,46...|\n",
      "| 95.0| 200.5074117194099|(104,[0,4,8,35,45...|\n",
      "|105.0|128.48438720450395|(104,[0,4,8,36,46...|\n",
      "|125.0|108.70731811393489|(104,[0,4,8,36,45...|\n",
      "|405.0|444.05924130765334|(104,[0,4,8,16,50...|\n",
      "| 72.0|187.88334714553457|(104,[0,4,8,16,47...|\n",
      "|150.0|185.72996926754968|(104,[0,4,8,21,47...|\n",
      "|450.0|268.26018917100646|(104,[0,4,8,22,47...|\n",
      "|165.0|357.28925461431845|(104,[0,4,8,10,47...|\n",
      "| 85.0|200.10202003698168|(104,[0,4,8,10,47...|\n",
      "|100.0| 187.3679853991889|(104,[0,4,8,19,46...|\n",
      "|100.0| 52.38409496248187|(104,[0,4,8,30,45...|\n",
      "| 57.0|203.43439302167099|(104,[0,4,8,29,45...|\n",
      "| 99.0| 277.2300165159686|(104,[0,4,8,29,45...|\n",
      "|165.0| 445.4617629407994|(104,[0,4,8,29,47...|\n",
      "|410.0|473.10293052621455|(104,[0,4,8,32,46...|\n",
      "+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('price', 'prediction', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spark.ml there are classification, regression, clustering, and ranking evaluators (introduced in Spark 3.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE (root mean square error)\n",
    "\n",
    "use this and R2 since regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction',\n",
    "    labelCol='price',\n",
    "    metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 286.2\n"
     ]
    }
   ],
   "source": [
    "rmse = regressionEvaluator.setMetricName('rmse').evaluate(predDF)\n",
    "print(f'RMSE is {rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.19910175951"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionEvaluator.evaluate(predDF, {regressionEvaluator.metricName: 'rmse'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.50341120810286"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionEvaluator.evaluate(predDF, {regressionEvaluator.metricName: 'mae'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(price)|\n",
      "+------------------+\n",
      "|214.60020840569643|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(avg('price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(avg(price)=214.60020840569643)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select(avg('price')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214.60020840569643"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select(avg('price')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPrice = trainDF.select(avg('price')).first()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't need to do a `model.transform(testDF)` to get a prediction.\n",
    "\n",
    "Instead, we are assigning the average price as the prediction value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF_baseline = testDF.withColumn('avgPrediction', lit(avgPrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'host_total_listings_count',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'price',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na',\n",
       " 'avgPrediction']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDF_baseline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionMeanEvaluator = RegressionEvaluator(predictionCol='avgPrediction', labelCol='price', metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for predicting avg price is: 311.16\n"
     ]
    }
   ],
   "source": [
    "rmse_baseline = regressionMeanEvaluator.evaluate(predDF_baseline)\n",
    "print(f'RMSE for predicting avg price is: {rmse_baseline:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE model: 286.20\n",
      "RMSE baseline: 311.16\n",
      "The model beat the baseline.\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE model: {rmse:.2f}\\nRMSE baseline: {rmse_baseline:.2f}')\n",
    "print('The model beat the baseline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $R^2$ values range from $(-\\infty, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "R^2 &= 1 - \\frac{SS_{res}}{SS_{tot}} \\\\\n",
    "SS_{tot} &= \\sum_{i=1}^n (y_i - \\bar{y})^2 \\\\\n",
    "SS_{res} &= \\sum_{i=1}^n (y_i - \\hat{y})^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = regressionEvaluator.setMetricName('r2').evaluate(predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15360837656049942"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionEvaluator.evaluate(predDF, {regressionEvaluator.metricName: 'r2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15360837656049942"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0003858279473081261"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 - (1 - (rmse/rmse_baseline)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict price on log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "logTrainDF = trainDF.withColumn('log_price', log(col('price')))\n",
    "logTestDF = testDF.withColumn('log_price', log(col('price')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lr = LinearRegression(labelCol='log_price', featuresCol='features', predictionCol='log_pred')\n",
    "log_pipeline = Pipeline(stages = stages_cat_str_index + [oheEncoder, vecAssembler, log_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[host_is_superhost: string, cancellation_policy: string, instant_bookable: string, host_total_listings_count: double, neighbourhood_cleansed: string, latitude: double, longitude: double, property_type: string, room_type: string, accommodates: double, bathrooms: double, bedrooms: double, beds: double, bed_type: string, minimum_nights: double, number_of_reviews: double, review_scores_rating: double, review_scores_accuracy: double, review_scores_cleanliness: double, review_scores_checkin: double, review_scores_communication: double, review_scores_location: double, review_scores_value: double, price: double, bedrooms_na: double, bathrooms_na: double, beds_na: double, review_scores_rating_na: double, review_scores_accuracy_na: double, review_scores_cleanliness_na: double, review_scores_checkin_na: double, review_scores_communication_na: double, review_scores_location_na: double, review_scores_value_na: double, log_price: double, host_is_superhost_Index: double, cancellation_policy_Index: double, instant_bookable_Index: double, neighbourhood_cleansed_Index: double, property_type_Index: double, room_type_Index: double, bed_type_Index: double, property_type_OHE: vector, room_type_OHE: vector, instant_bookable_OHE: vector, bed_type_OHE: vector, cancellation_policy_OHE: vector, host_is_superhost_OHE: vector, neighbourhood_cleansed_OHE: vector, features: vector, log_pred: double]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pipeline_model = log_pipeline.fit(logTrainDF)\n",
    "\n",
    "log_predDF = log_pipeline_model.transform(logTestDF)\n",
    "\n",
    "log_predDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'host_total_listings_count',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'price',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na',\n",
       " 'log_price',\n",
       " 'host_is_superhost_Index',\n",
       " 'cancellation_policy_Index',\n",
       " 'instant_bookable_Index',\n",
       " 'neighbourhood_cleansed_Index',\n",
       " 'property_type_Index',\n",
       " 'room_type_Index',\n",
       " 'bed_type_Index',\n",
       " 'property_type_OHE',\n",
       " 'room_type_OHE',\n",
       " 'instant_bookable_OHE',\n",
       " 'bed_type_OHE',\n",
       " 'cancellation_policy_OHE',\n",
       " 'host_is_superhost_OHE',\n",
       " 'neighbourhood_cleansed_OHE',\n",
       " 'features',\n",
       " 'log_pred']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_predDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, exp\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+\n",
      "|price|        prediction|          log_pred|\n",
      "+-----+------------------+------------------+\n",
      "|130.0| 64.90612595675911| 4.172942009960593|\n",
      "| 85.0|103.75846825102599| 4.642065777476574|\n",
      "| 95.0|117.26581005219721| 4.764443238766688|\n",
      "|128.0| 47.53748348391692|3.8615185258215945|\n",
      "|250.0|107.07401774424223| 4.673520349929049|\n",
      "| 95.0|159.17878797836354| 5.070028023190929|\n",
      "|105.0|110.26373784158828| 4.702875112837148|\n",
      "|125.0|123.76142608947094|4.8183557292225885|\n",
      "|405.0| 378.0789841136678|5.9351031264736775|\n",
      "| 72.0|135.11715474504877| 4.906142215032787|\n",
      "|150.0| 161.5131508284563| 5.084586568625895|\n",
      "|450.0| 147.4394921654137| 4.993417869008198|\n",
      "|165.0|243.79652313459525| 5.496333955807643|\n",
      "| 85.0|123.53302787706579|4.8165085525173765|\n",
      "|100.0|119.54310069714214| 4.783676981633761|\n",
      "|100.0|109.49555077883437| 4.695883916274283|\n",
      "| 57.0|115.30904518886132| 4.747615873364225|\n",
      "| 99.0|185.54644286828037| 5.223305216577927|\n",
      "|165.0| 281.4170711500708| 5.639837807908009|\n",
      "|410.0| 259.9842664508151| 5.560621115533792|\n",
      "+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_predDF.withColumn('prediction', exp(col('log_pred'))).select('price', 'prediction', 'log_pred').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "expDF = log_predDF.withColumn('prediction', exp(col('log_pred')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 286.20\n",
      "r2: 0.15\n",
      "\n",
      "log RMSE: 278.56\n",
      "log r2: 0.20\n"
     ]
    }
   ],
   "source": [
    "log_regr_eval = RegressionEvaluator(labelCol='price', predictionCol='prediction')\n",
    "log_rmse = log_regr_eval.setMetricName('rmse').evaluate(expDF)\n",
    "log_r2 = log_regr_eval.setMetricName('r2').evaluate(expDF)\n",
    "\n",
    "print(f'RMSE: {rmse:.2f}')\n",
    "print(f'r2: {r2:.2f}')\n",
    "print()\n",
    "print(f'log RMSE: {log_rmse:.2f}')\n",
    "print(f'log r2: {log_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: prices are lognormal (the log of the prices is a normal distribution)\n",
    "\n",
    "building a model to predict log prices, then exponentiating to get actual price results in a lower RMSE and higher $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelinePath = './lr-pipeline-model'\n",
    "(pipelineModel\n",
    " .write()\n",
    " .overwrite()\n",
    " .save(pipelinePath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading you need to specify the type of model you are loading (e.g. `LinearRegressionModel` or `LogisticRegressionModel`).\n",
    "\n",
    "If you always put transformers/estimators in a `Pipeline`, then you'll always load a `PipelineModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "savedPipelineModel = PipelineModel.load(pipelinePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_saved = savedPipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.19910175951"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionEvaluator.setMetricName('rmse').evaluate(pred_df_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 286.19910175951\n",
      "R2: 0.15360837656049942\n"
     ]
    }
   ],
   "source": [
    "print(f'rmse: {regressionEvaluator.setMetricName(\"rmse\").evaluate(pred_df_saved)}')\n",
    "print(f'R2: {regressionEvaluator.setMetricName(\"r2\").evaluate(pred_df_saved)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
