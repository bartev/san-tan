{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%load_ext blackcellmagic\n",
    "# in a cell, type %%black\n",
    "\n",
    "%load_ext autoreload\n",
    "# in a cell, type %autoreload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "\n",
    "import src.data.utils as uts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[*]')\n",
    "         .appName(\"spark-ml-ch-11\")\n",
    "         .config('ui.showConsoleProgress', 'false')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `src.data.utils`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Library versioning\n",
    "* Data evolution\n",
    "* Order of execution\n",
    "* Parallel operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow\n",
    "https://mlflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is an open source platform that helps developers reproduce and share experiments, manage models, and much more. It provides interfaces in Python, R, and Java/Scala, as well as a REST API. As shown in Figure 11-1, MLflow has four main components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tracking\n",
    "    * Provides APIs to record parameters, metrics, code versions, models, and artifacts such as plots, and text.\n",
    "* Projects\n",
    "    * A standardized format to package your data science projects and their dependencies to run on other platforms. It helps you manage the model training process.\n",
    "* Models\n",
    "    * A standardized format to package models to deploy to diverse execution environments. It provides a consistent API for loading and applying models, regardless of the algorithm or library used to build the model.\n",
    "* Registry\n",
    "    * A repository to keep track of model lineage, model versions, stage transitions, and annotations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s examine a few things that can be logged to the tracking server:\n",
    "\n",
    "* Parameters\n",
    "    * Key/value inputs to your code—e.g., hyperparameters like num_trees or max_depth in your random forest\n",
    "* Metrics\n",
    "    * Numeric values (can update over time)—e.g., RMSE or accuracy values\n",
    "* Artifacts\n",
    "    * Files, data, and models—e.g., matplotlib images, or Parquet files\n",
    "* Metadata\n",
    "    * Information about the run, such as the source code that executed the run or the version of the code (e.g., the Git commit hash string for the code version)\n",
    "* Models\n",
    "    * The model(s) you trained\n",
    "\n",
    "\n",
    "By default, the tracking server records everything to the filesystem, but you can specify a database for faster querying, such as for the parameters and metrics. Let’s add MLflow tracking to our random forest code from Chapter 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "filePath = db_fname(\"sf-airbnb/sf-airbnb-clean.parquet\")\n",
    "airbnbDF = spark.read.parquet(filePath)\n",
    "\n",
    "(trainDF, testDF) = airbnbDF.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.train_model as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == 'string']\n",
    "\n",
    "stages_string_indexer = tm.make_string_indexer_list(categoricalCols)\n",
    "\n",
    "indexOutputCols = [indexer.getOutputCol() for indexer in stages_string_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [field for (field, dataType) in trainDF.dtypes\n",
    "                  if ((dataType == 'double') & (field != 'price'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "                              outputCol='features')\n",
    "\n",
    "rf = RandomForestRegressor(labelCol='price', maxBins=40, maxDepth=5, numTrees=100, seed=42)\n",
    "\n",
    "stages = stages_string_indexer + [vecAssembler, rf]\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
