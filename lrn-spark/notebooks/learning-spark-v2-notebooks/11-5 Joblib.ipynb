{"cells":[{"cell_type":"markdown","source":["d\n# Joblib\n\nThis notebook uses [Joblib](https://github.com/joblib/joblib) to parallelize the evaluation of sklearn models. \n\n**NOTE**: You will need to install `joblibspark` on your cluster for the code below."],"metadata":{}},{"cell_type":"code","source":["from sklearn.utils import parallel_backend\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport pandas as pd\nfrom joblibspark import register_spark\n\nregister_spark() # register spark backend\n\ndf = pd.read_csv(\"/dbfs/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-numeric.csv\").drop([\"zipcode\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(df.drop([\"price\"], axis=1), df[[\"price\"]].values.ravel(), random_state=42)\n\nrf = RandomForestRegressor(random_state=42)\nparam_grid = {\"max_depth\": [2, 5, 10], \"n_estimators\": [20, 50, 100]}\ngscv = GridSearchCV(rf, param_grid, cv=3)\n\nwith parallel_backend(\"spark\", n_jobs=3):\n  gscv.fit(X_train, y_train)\n  \n# Uses R2 to score the models\nprint(gscv.cv_results_)\nprint(gscv.best_estimator_)\n"],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"11-5 Joblib","notebookId":3114109954854693},"nbformat":4,"nbformat_minor":0}
